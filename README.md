# ARwrite
Air writing using object based motion following and Image Processing

## Introduction

* Have you ever had a moment of inspiration but have nothing around
you to write your idea down? Have you ever thought about making
notes anywhere and anytime without a pen-paper and being able to
project what you write to multiple screens for presentations?
* We had the exact same thoughts during our recently concluded
semester exams, which would have helped improved our preparation
considerably.
* Therefore we intend to create a solutions for the above by using a
raspberry pi, a camera and python programming. It will help us quickly
visualise what's in our heads. This concept could also be incorporated
into our smart classes.

## Methodology

* Emulate writing in the air with smart glasses.
* When you move your hand or pen, the camera will trace your
movement and display whatever shape you create.
* To build our prototype, we will use a Raspberry Pi, possible mounting it
on our heads as a cap since we can't access actual smart glasses and
display it on a monitor.
* The movement will be recorded by using colour based object
detection and tracking with OpenCV.

## Block Diagram

![image](https://user-images.githubusercontent.com/51409005/148342459-c4a8ba66-0b9a-45c6-afff-023547c34508.png)

Note - This version of the code runs on PC and would need to be modifed to work on a Raspberry Pi.
